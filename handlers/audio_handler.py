import threading
import logging
import time
import queue
import numpy as np 
import torch
import re
import asyncio
from websockets.sync.client import connect
from websockets.exceptions import ConnectionClosed, InvalidStatusCode

from handlers.llm_handler import llm_response, get_summary_response, get_title_response
from utils.kb_requests import save_info_in_kb, get_info_from_kb
from config.config import (STREAM_SAMPLE_RATE, STREAM_TRIGGER_WORD, STREAM_STOP_WORD_1, STREAM_STOP_WORD_2, MEET_AUDIO_CHUNKS_DIR,
                        STREAM_STOP_WORD_3, MEET_FRAME_DURATION_MS, SUMMARY_OUTPUT_DIR)
from config.load_models import create_new_vad_model
from utils.backend_request import send_results_to_backend

logger = logging.getLogger(__name__)

class AudioHandler:
    def __init__(self, meeting_id, audio_queue, is_running, email, send_chat_message, stop):
        self.meeting_id = meeting_id
        self.audio_queue = audio_queue
        self.is_running = is_running
        self.vad = create_new_vad_model()
        # self.asr_model = asr_model # –ú–æ–¥–µ–ª—å –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º WS
        self.email = email
        self.start_time = time.time()

        self.global_offset = 0.0
        self.all_segments = []

        self.summary_output_dir = SUMMARY_OUTPUT_DIR # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è summary
        self.output_dir = MEET_AUDIO_CHUNKS_DIR / self.meeting_id 

        self.send_chat_message = send_chat_message
        self.stop = stop
        
        self.ws_url = "ws://localhost:8000/transcribe"
        self.ws_connection = None

    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
    def format_time_hms(self, seconds: float) -> str:
        h = int(seconds // 3600)
        m = int((seconds % 3600) // 60)
        s = int(seconds % 60)
        return f"{h:02d}:{m:02d}:{s:02d}"

    def _connect_websocket(self):
        """–£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç WS —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Inference Service —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏."""
        while self.is_running.is_set():
            try:
                self.ws_connection = connect(self.ws_url)
                logger.info(f"[{self.meeting_id}] ‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–æ –∫ Inference Service (WS).")
                return
            except Exception as e:
                logger.warning(f"[{self.meeting_id}] ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ Inference Service: {e}. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ 2—Å...")
                time.sleep(2)

    def _send_audio_to_service(self, audio_bytes: bytes) -> str:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∞—É–¥–∏–æ –∏ –ø–æ–ª—É—á–∞–µ—Ç —Ç–µ–∫—Å—Ç."""
        if not self.ws_connection:
            self._connect_websocket()
        
        start_ts = time.time()
        try:
            # logger.info(f"[{self.meeting_id}] Sending audio chunk: {len(audio_bytes)} bytes")
            self.ws_connection.send(audio_bytes)
            text = self.ws_connection.recv()
            
            latency = time.time() - start_ts
            if text:
                logger.info(f"[{self.meeting_id}] Transcribe latency: {latency:.3f}s. Text: {str(text)[:50]}...")
            
            return str(text)
        except (ConnectionClosed, InvalidStatusCode) as e:
            logger.warning(f"[{self.meeting_id}] üîå –†–∞–∑—Ä—ã–≤ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è WS: {e}. –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ...")
            self._connect_websocket()
            # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –æ—Ç–ø—Ä–∞–≤–∫–∞ (–æ–¥–∏–Ω —Ä–∞–∑)
            try:
                start_ts = time.time()
                self.ws_connection.send(audio_bytes)
                text = self.ws_connection.recv()
                latency = time.time() - start_ts
                logger.info(f"[{self.meeting_id}] Transcribe latency (retry): {latency:.3f}s. Text: {str(text)[:50]}...")
                return str(text)
            except Exception as e2:
                 logger.error(f"[{self.meeting_id}] ‚ùå –û—à–∏–±–∫–∞ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–∏: {e2}")
                 return ""
        except Exception as e:
            logger.error(f"[{self.meeting_id}] ‚ùå –û—à–∏–±–∫–∞ WS: {e}")
            return ""

    def _handle_transcription_logic(self, transcription, pipeline_start_time):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª—É—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç (—Ç—Ä–∏–≥–≥–µ—Ä—ã, –æ—Ç–≤–µ—Ç—ã LLM)."""
        if transcription.lower().lstrip().startswith(STREAM_TRIGGER_WORD):
            clean_transcription = ''.join(char for char in transcription.lower() if char.isalnum() or char.isspace())

            if STREAM_STOP_WORD_1 in clean_transcription or STREAM_STOP_WORD_2 in clean_transcription or STREAM_STOP_WORD_3 in clean_transcription:
                logger.info(f"[{self.meeting_id}] –ü—Ä–æ–≤–æ–∂—É –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É –∏ –∑–∞–≤–µ—Ä—à–∞—é —Ä–∞–±–æ—Ç—É")
                self.send_chat_message("–£—Å–ª—ã—à–∞–ª–∞ –í–∞—Å, –∑–∞–≤–µ—Ä—à–∞—é —Ä–∞–±–æ—Ç—É!")
                self.stop()
            else:
                self.send_chat_message("–£—Å–ª—ã—à–∞–ª–∞ –í–∞—Å, –¥–µ–π—Å—Ç–≤—É—é...")
                try:
                    key, response = llm_response(transcription)
                    logger.info(f"–û—Ç–≤–µ—Ç –æ—Ç LLM: {key, response}")
                    if response:
                        print("–û—Ç–ø—Ä–∞–≤–ª—è—é –æ—Ç–≤–µ—Ç –≤ —á–∞—Ç...")
                    if key == 0:
                        asyncio.run(save_info_in_kb(response, self.email))
                        self.send_chat_message("–í–∞—à–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.")
                    elif key == 1:
                        info_from_kb = asyncio.run(get_info_from_kb(response, self.email))
                        if info_from_kb == None:
                            self.send_chat_message("–ù–µ –Ω–∞—à–ª–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –≤–∞—à–µ–π –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π.")
                        else:
                            self.send_chat_message(info_from_kb)
                    elif key == 3:
                        self.send_chat_message(response)

                except Exception as chat_err:
                    logger.error(f"[{self.meeting_id}] –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –æ—Ç–≤–µ—Ç–∞ –≤ —á–∞—Ç: {chat_err}")

    def _process_speech_buffer(self, speech_buffer, start_ts, end_ts, min_duration=0.5):
        """–°–æ–±–∏—Ä–∞–µ—Ç –∞—É–¥–∏–æ –∏–∑ –±—É—Ñ–µ—Ä–∞, –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –Ω–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç."""
        if not speech_buffer:
            return

        full_audio_np = np.concatenate(speech_buffer)
        chunk_duration = len(full_audio_np) / STREAM_SAMPLE_RATE

        if chunk_duration < min_duration:
            return

        # –û–¢–ü–†–ê–í–ö–ê –ù–ê –°–ï–†–í–ï–† (WS)
        transcribed_text = self._send_audio_to_service(full_audio_np.tobytes())
        
        if not transcribed_text:
            return

        dialog = f"[{self.format_time_hms(start_ts)} - {self.format_time_hms(end_ts)}] {transcribed_text.strip()}"
        
        self.all_segments.append(dialog)
        print(dialog)

        # –ß–∏—Å—Ç—ã–π —Ç–µ–∫—Å—Ç –±–µ–∑ —Ç–∞–π–º–∏–Ω–≥–æ–≤
        transcription = re.sub(r"\[\d{2}:\d{2}:\d{2}\s*-\s*\d{2}:\d{2}:\d{2}\]\s*", "", dialog)
        
        self.global_offset += chunk_duration
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ª–æ–≥–∏–∫–∏ (—Ç—Ä–∏–≥–≥–µ—Ä—ã –∏ —Ç.–¥.)
        self._handle_transcription_logic(transcription, None)

    # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ–ø–æ—Ç–æ–∫–∞ -- —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è -- –æ—Ç–≤–µ—Ç (–µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —Ç—Ä–∏–≥–≥–µ—Ä)
    def _process_audio_stream(self):
        threading.current_thread().name = f'VADProcessor-{self.meeting_id}'
        logger.info(f"[{self.meeting_id}] VAD –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –∑–∞–ø—É—â–µ–Ω (Silero).")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø–æ—Ç–æ–∫–∞
        self._connect_websocket()

        vad_buffer = None
        # Silero VAD –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ 512 —Å—ç–º–ø–ª–æ–≤ (–ø—Ä–∏ 16k)
        VAD_CHUNK_SIZE = 512
        # –ë—É—Ñ–µ—Ä –¥–ª—è –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è —á–∞–Ω–∫–æ–≤ –ø–µ—Ä–µ–¥ –ø—Ä–æ–≥–æ–Ω–æ–º —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å (–æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è)
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–∞—á–∫–æ–π, –Ω–æ –ø–æ–¥–∞–µ–º –≤ –º–æ–¥–µ–ª—å –∫—É—Å–æ—á–∫–∞–º–∏ –ø–æ 512
        accumulated_chunks = []
        
        speech_buffer_for_asr = []
        is_speaking = False
        recent_probs = []                     # –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
        vad_threshold = 0.3                   # –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —Ä–µ—á–∏
        silence_duration_ms = 600             # —Å–∫–æ–ª—å–∫–æ —Ç–∏—à–∏–Ω—ã –Ω—É–∂–Ω–æ –¥–ª—è –∫–æ–Ω—Ü–∞ —Ä–µ—á–∏
        min_speech_duration = 0.5             # –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ä–µ—á–∏
        MAX_SPEECH_DURATION_S = 30.0          # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ —Ä–µ—á–∏ –ø–µ—Ä–µ–¥ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –æ—Ç–ø—Ä–∞–≤–∫–æ–π
        sr = STREAM_SAMPLE_RATE

        silence_accum_ms = 0
        speech_start_walltime = None

        # –¢–∞–π–º–µ—Ä –¥–ª—è –≤—Å–µ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ—á–∏
        pipeline_start_time = None

        while self.is_running.is_set():
            try:
                audio_frame_bytes = self.audio_queue.get(timeout=1)
                if not audio_frame_bytes:
                    continue

                audio_np = np.frombuffer(audio_frame_bytes, dtype=np.int16).astype(np.float32) / 32768.0
                new_audio_tensor = torch.from_numpy(audio_np)

                if vad_buffer is None:
                    vad_buffer = new_audio_tensor
                else:
                    vad_buffer = torch.cat([vad_buffer, new_audio_tensor])

                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ, –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –º–æ–¥–µ–ª—å
                device = next(self.vad.parameters()).device

                while vad_buffer is not None and vad_buffer.shape[0] >= VAD_CHUNK_SIZE:
                    chunk_to_process = vad_buffer[:VAD_CHUNK_SIZE]
                    vad_buffer = vad_buffer[VAD_CHUNK_SIZE:]

                    # –ü–µ—Ä–µ–Ω–æ—Å–∏–º —á–∞–Ω–∫ –Ω–∞ —Ç–æ –∂–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ, —á—Ç–æ –∏ –º–æ–¥–µ–ª—å (GPU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
                    chunk_to_process_device = chunk_to_process.to(device)
                    
                    # –í–ê–ñ–ù–û: Silero VAD —Ç—Ä–µ–±—É–µ—Ç —Ç–æ—á–Ω—ã–π —Ä–∞–∑–º–µ—Ä –≤—Ö–æ–¥–∞ (512), –±–∞—Ç—á–∏–Ω–≥ –≤–Ω—É—Ç—Ä–∏ –º–æ–¥–µ–ª–∏ –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è "–∏–∑ –∫–æ—Ä–æ–±–∫–∏" –¥–ª—è streaming
                    # –ü–æ—ç—Ç–æ–º—É –≤—ã–∑—ã–≤–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —á–∞–Ω–∫–∞ 512, –Ω–æ —Å–∞–º —á–∞–Ω–∫ —É–∂–µ –Ω–∞ GPU
                    speech_prob = self.vad(chunk_to_process_device, sr).item()

                    recent_probs.append(speech_prob)
                    if len(recent_probs) > 3:
                        recent_probs.pop(0)
                    smooth_prob = sum(recent_probs) / len(recent_probs)

                    now = time.time()
                    meeting_elapsed_sec = now - self.start_time

                    if smooth_prob > vad_threshold:
                        if not is_speaking:
                            logger.info(f"[{self.meeting_id}] ‚ñ∂Ô∏è –ù–∞—á–∞–ª–æ —Ä–µ—á–∏")
                            is_speaking = True
                            speech_start_walltime = meeting_elapsed_sec
                            pipeline_start_time = time.time()  # –ó–∞–ø—É—Å–∫ —Ç–∞–π–º–µ—Ä–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞

                        speech_buffer_for_asr.append(chunk_to_process.numpy())
                        silence_accum_ms = 0
                        
                        # --- –ü–†–û–í–ï–†–ö–ê –ù–ê –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–£–Æ –î–õ–ò–¢–ï–õ–¨–ù–û–°–¢–¨ ---
                        current_duration_s = (len(speech_buffer_for_asr) * VAD_CHUNK_SIZE) / sr
                        if current_duration_s >= MAX_SPEECH_DURATION_S:
                            logger.info(f"[{self.meeting_id}] ‚úÇÔ∏è –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—Ç—Å–µ—á–∫–∞ —Ä–µ—á–∏ –ø–æ —Ç–∞–π–º-–∞—É—Ç—É ({MAX_SPEECH_DURATION_S}—Å)")
                            
                            # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–Ω–µ—Ü —Ç–µ–∫—É—â–µ–≥–æ –∫—É—Å–∫–∞
                            speech_end_walltime = speech_start_walltime + current_duration_s
                            
                            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π –±—É—Ñ–µ—Ä
                            self._process_speech_buffer(speech_buffer_for_asr, speech_start_walltime, speech_end_walltime, min_speech_duration)
                            
                            # –û—á–∏—â–∞–µ–º –±—É—Ñ–µ—Ä –∏ –æ–±–Ω–æ–≤–ª—è–µ–º –Ω–∞—á–∞–ª–æ —Å–ª–µ–¥—É—é—â–µ–≥–æ –∫—É—Å–∫–∞
                            speech_buffer_for_asr.clear()
                            speech_start_walltime = speech_end_walltime # –°–ª–µ–¥—É—é—â–∏–π –∫—É—Å–æ–∫ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å—Ä–∞–∑—É
                            # is_speaking –æ—Å—Ç–∞–µ—Ç—Å—è True, —Ç–∞–∫ –∫–∞–∫ –º—ã –≤—Å–µ –µ—â–µ –≤ –±–ª–æ–∫–µ "—Ä–µ—á—å –∏–¥–µ—Ç"

                    else:
                        if is_speaking:
                            silence_accum_ms += (VAD_CHUNK_SIZE / sr) * 1000
                            if silence_accum_ms >= silence_duration_ms:

                                if speech_buffer_for_asr:
                                    chunk_duration = (len(speech_buffer_for_asr) * VAD_CHUNK_SIZE) / sr
                                    speech_end_walltime = speech_start_walltime + chunk_duration
                                    
                                    self._process_speech_buffer(speech_buffer_for_asr, speech_start_walltime, speech_end_walltime, min_speech_duration)
                                    speech_buffer_for_asr.clear()

                                is_speaking = False
                                silence_accum_ms = 0
                                pipeline_start_time = None

            except queue.Empty:
                if is_speaking and speech_buffer_for_asr:
                    logger.info(f"[{self.meeting_id}] –¢–∞–π–º-–∞—É—Ç, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à—É—é—Å—è —Ä–µ—á—å.")
                    chunk_duration = (len(speech_buffer_for_asr) * VAD_CHUNK_SIZE) / sr
                    speech_end_walltime = speech_start_walltime + chunk_duration
                    self._process_speech_buffer(speech_buffer_for_asr, speech_start_walltime, speech_end_walltime, min_speech_duration)
                    speech_buffer_for_asr.clear()
                    is_speaking = False
                continue
            except Exception as e:
                logger.error(f"[{self.meeting_id}] –û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ VAD: {e}", exc_info=True)
        
        # –ó–∞–∫—Ä—ã–≤–∞–µ–º —Å–æ–∫–µ—Ç
        if self.ws_connection:
            try:
                self.ws_connection.close()
            except:
                pass

    # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞: –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∞—É–¥–∏–æ—á–∞–Ω–∫–æ–≤ -- –∑–∞–ø—É—Å–∫ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏ –∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–µ–π -- —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è -- –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ -- –æ—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –≤–Ω–µ—à–Ω–∏–π —Å–µ—Ä–≤–µ—Ä
    def _perform_post_processing(self):
        threading.current_thread().name = f'PostProcessor-{self.meeting_id}'
        logger.info(f"[{self.meeting_id}] –ù–∞—á–∏–Ω–∞—é –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫—É...")

        try:

            full = "\n".join(self.all_segments)
        
            print(f"–§–∏–Ω–∞–ª—å–Ω—ã–π –¥–∏–∞–ª–æ–≥: \n {full}")

            now = time.time()
            meeting_elapsed_sec = now - self.start_time

            # –û—á–∏—Å—Ç–∫–∞ –¥–∏–∞–ª–æ–≥–∞ –æ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–µ—Ç–æ–∫
            cleaned_dialogue = re.sub(r"\[\d{2}:\d{2}:\d{2}\s*-\s*\d{2}:\d{2}:\d{2}\]\s*", "", full).strip()

            summary_text = ""
            title_text = ""
            
            if cleaned_dialogue:
                # –°—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è
                logger.info(f"[{self.meeting_id}] –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ...")
                summary_text = get_summary_response(cleaned_dialogue)
                print(f"–≠—Ç–æ –≤—ã–≤–æ–¥ summary: \n{summary_text}")
                
                # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
                logger.info(f"[{self.meeting_id}] –°–æ–∑–¥–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞...")
                title_text = get_title_response(cleaned_dialogue)
                print(f"–≠—Ç–æ –≤—ã–≤–æ–¥ –∑–∞–≥–æ–ª–æ–≤–∫–∞: \n{title_text}")

                # –û—Ç–ø—Ä–∞–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ –≤–Ω–µ—à–Ω–∏–π —Å–µ—Ä–≤–µ—Ä
                send_results_to_backend(self.meeting_id, full, summary_text, title_text, int(meeting_elapsed_sec))
            else:
                logger.warning(f"[{self.meeting_id}] –î–∏–∞–ª–æ–≥ –ø—É—Å—Ç, –ø—Ä–æ–ø—É—Å–∫–∞—é —Å–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—é–º–µ –∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞.")
            

        except Exception as e:
            logger.error(f"[{self.meeting_id}] ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}", exc_info=True)
        finally:
            logger.info(f"[{self.meeting_id}] –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")
