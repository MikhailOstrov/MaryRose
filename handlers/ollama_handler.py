import requests
import os
import time

OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
OLLAMA_MODEL = "llama3:8b-instruct-q4_K_M"

def ensure_model_available():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –º–æ–¥–µ–ª–∏ –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –µ—ë –µ—Å–ª–∏ –Ω—É–∂–Ω–æ"""
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=10)
        response.raise_for_status()
        models = response.json().get('models', [])
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –Ω—É–∂–Ω–∞—è –º–æ–¥–µ–ª—å
        model_exists = any(OLLAMA_MODEL in model.get('name', '') for model in models)
        
        if model_exists:
            print(f"‚úÖ –ú–æ–¥–µ–ª—å {OLLAMA_MODEL} –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
            return True
            
        print(f"üì• –ó–∞–≥—Ä—É–∂–∞—é –º–æ–¥–µ–ª—å {OLLAMA_MODEL}...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        pull_response = requests.post(
            f"{OLLAMA_BASE_URL}/api/pull",
            json={"name": OLLAMA_MODEL},
            timeout=600  # 10 –º–∏–Ω—É—Ç –Ω–∞ –∑–∞–≥—Ä—É–∑–∫—É
        )
        pull_response.raise_for_status()
        print(f"‚úÖ –ú–æ–¥–µ–ª—å {OLLAMA_MODEL} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        return True
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å –º–æ–¥–µ–ª—å—é: {e}")
        return False

# –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ –º–æ–¥—É–ª—è
print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Ollama...")
ensure_model_available()



OLLAMA_ASSISTANT_PROMPT = """
–¢—ã ‚Äî —É–º–Ω—ã–π —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫ –ø–æ –∏–º–µ–Ω–∏ –ú—ç—Ä–∏. –û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ —Å—É—â–µ—Å—Ç–≤—É.

–ö–æ–º–∞–Ω–¥–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: "{command}"

–î–∞–π —á–µ—Ç–∫–∏–π –∏ –ø–æ–ª–µ–∑–Ω—ã–π –æ—Ç–≤–µ—Ç:
"""

OLLAMA_SUMMARY_PROMPT = """
–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –≤—Å—Ç—Ä–µ—á. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –¥–∏–∞–ª–æ–≥ –∏ —Å–æ–∑–¥–∞–π –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.

–í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ!

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞:

### –ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã
- [–ì–ª–∞–≤–Ω–∞—è —Ç–µ–º–∞ –∏–ª–∏ —Ä–µ—à–µ–Ω–∏–µ 1]
- [–ì–ª–∞–≤–Ω–∞—è —Ç–µ–º–∞ –∏–ª–∏ —Ä–µ—à–µ–Ω–∏–µ 2]
- [–¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã...]

### –ü–æ—Ä—É—á–µ–Ω–∏—è –∏ –∑–∞–¥–∞—á–∏
- **[–ò–º—è]:** [–ß—Ç–æ –ø–æ—Ä—É—á–µ–Ω–æ —Å–¥–µ–ª–∞—Ç—å]
- **[–ò–º—è]:** [–î—Ä—É–≥–∞—è –∑–∞–¥–∞—á–∞]

### –†–µ—à–µ–Ω–∏—è
- [–ü—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ—à–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥—ã]

–î–∏–∞–ª–æ–≥ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
---
{dialogue_text}
---

–†–µ–∑—é–º–µ:
"""

def _call_ollama(prompt: str) -> str:
    """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ Ollama –∏ –ø–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç"""
    data = {"model": OLLAMA_MODEL, "prompt": prompt, "stream": False}
    
    try:
        response = requests.post(f"{OLLAMA_BASE_URL}/api/generate", json=data, timeout=30.0)
        response.raise_for_status()
        return response.json().get('response', '')
    except requests.exceptions.RequestException as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ Ollama: {e}")
        return ""

def get_mary_response(command: str) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç –æ—Ç–≤–µ—Ç –æ—Ç –ú—ç—Ä–∏ –Ω–∞ –∫–æ–º–∞–Ω–¥—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    prompt = OLLAMA_ASSISTANT_PROMPT.format(command=command)
    response_text = _call_ollama(prompt)
    if not response_text:
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, —É –º–µ–Ω—è –ø—Ä–æ–±–ª–µ–º—ã —Å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º."
    return response_text.strip()

def get_summary_response(dialogue_text: str) -> str:
    """–°–æ–∑–¥–∞–µ—Ç —Ä–µ–∑—é–º–µ –¥–∏–∞–ª–æ–≥–∞ —Å –ø–æ–º–æ—â—å—é Ollama"""
    prompt = OLLAMA_SUMMARY_PROMPT.format(dialogue_text=dialogue_text)
    response_text = _call_ollama(prompt)
    if not response_text:
        return "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ä–µ–∑—é–º–µ –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏."
    return response_text.strip()