# MaryRose AI Meeting Bot

Это серверная часть проекта "MaryRose", AI-ассистента для совещаний в Google Meet. Система способна подключаться к встречам, записывать аудио, выполнять диаризацию (разделение по спикерам), транскрибацию (преобразование речи в текст) и суммаризацию.

## Основные технологии

- **FastAPI**: Для создания асинхронного API.
- **PyTorch / NeMo**: Для моделей распознавания речи (ASR) и диаризации.
- **Selenium / Undetected-Chromedriver**: Для автоматизации браузера и подключения к Google Meet.
- **PulseAudio**: Для перехвата системного звука внутри Docker-контейнера.
- **Docker / Docker Compose**: Для контейнеризации и оркестрации сервисов.

---

## Техническая документация: Интеграция бота для Google Meet

Эта документация описывает архитектуру и принципы работы бота-слушателя, интегрированного в основной бэкенд.

### 1. Инициализация и подключение бота

Процесс запуска бота и его подключения к встрече — это сложный механизм, который можно разбить на несколько этапов. Весь этот процесс инициируется вызовом метода `start()` у экземпляра класса `MeetListenerBot`, который находится в `api/meet_listener.py`.

**Пошаговый процесс запуска:**

1.  **Запуск в потоке:** Метод `start()` не выполняет работу сам. Он создает новый фоновый поток (`threading.Thread`), в котором запускает приватный метод `_run()`. Это сделано для того, чтобы основной процесс (наш FastAPI сервер) не блокировался и оставался отзывчивым, пока бот выполняет свою длительную работу.
2.  **Инициализация драйвера:** Первым шагом внутри `_run()` является вызов `_initialize_driver()`. Этот метод отвечает за запуск и настройку браузера Chrome, который будет нашим "окном" во встречу.
3.  **Присоединение к встрече:** Далее вызывается `join_meet_as_guest()`. Этот метод использует запущенный Chrome для перехода по `meet_url` и выполнения всех шагов для входа в качестве гостя.
4.  **Поиск аудиоустройства:** После успешного входа, метод `_find_device_id()` ищет в системе виртуальное аудиоустройство, созданное нашим `entrypoint.sh`.
5.  **Начало прослушивания:** Как только все готово, запускается цикл прослушивания аудиопотока с помощью библиотеки `sounddevice`, который будет работать до тех пор, пока бот не будет остановлен.

**Роль `_initialize_driver` и флаги Chrome:**

Этот метод — основа для стабильной работы браузера внутри Docker-контейнера. Он использует `undetected-chromedriver`, чтобы Chrome было сложнее опознать как автоматизированный. Ключевые флаги, которые мы используем:

- `--no-sandbox`: Критически важный флаг для запуска Chrome в контейнерах Docker. Он отключает песочницу безопасности Chrome, что необходимо при запуске от имени root-пользователя внутри контейнера.
- `--disable-dev-shm-usage`: В Docker общая память (`/dev/shm`) по умолчанию имеет небольшой размер. Этот флаг заставляет Chrome использовать временную папку `/tmp` вместо `/dev/shm`, предотвращая сбои браузера на больших страницах.
- `--user-data-dir`: Указывает Chrome, где хранить данные профиля (куки, сессии). Это позволяет боту "запоминать" входы и настройки между перезапусками, если это потребуется.
- `--autoplay-policy=no-user-gesture-required`: Разрешает автоматическое воспроизведение аудио на странице без необходимости клика со стороны пользователя. Это необходимо, чтобы мы вообще могли услышать звук со встречи.

**Подключение в гостевом режиме (`join_meet_as_guest`):**

Этот метод имитирует действия обычного пользователя:

1.  Открывает URL встречи.
2.  Ждет появления поля для ввода имени.
3.  Вводит имя гостя (из `config.py`).
4.  Нажимает кнопку "Попросить войти" (Ask to join).
5.  Терпеливо ждет, пока кто-то из участников встречи не одобрит запрос. Успешное присоединение определяется по появлению на странице иконки микрофона.

---

### 2. Работа новых API эндпоинтов

Управление ботом вынесено в API нашего `server.py` и осуществляется через три эндпоинта.

- `POST /api/v1/internal/start-processing`:
  - **Назначение:** Запускает новую сессию бота для Google Meet. Принимает `meeting_id` (уникальный идентификатор сессии) и `meet_url`.
- `POST /api/v1/internal/stop-processing`:
  - **Назначение:** Останавливает работающего бота по его `meeting_id`.
- `GET /status/{meeting_id}`:
  - **Назначение:** Позволяет проверить, активен ли бот для указанной встречи в данный момент.

**Управление состоянием и использование потоков:**

Для управления состоянием в `server.py` используется глобальный словарь `active_bots`. Ключом в этом словаре является `meeting_id`, а значением — экземпляр класса `MeetListenerBot`.

Когда приходит запрос на `/start-processing`, сервер сначала проверяет, нет ли уже в словаре `active_bots` ключа с таким `meeting_id`. Это простой, но эффективный механизм, который **гарантирует, что для одной и той же встречи не будет запущено несколько ботов одновременно.**

**Запуск бота в отдельном потоке является критически важным архитектурным решением.** Основная работа бота (ожидание в `sounddevice`) является блокирующей операцией. Если бы мы запустили ее в основном потоке FastAPI, наш сервер бы "завис" и перестал отвечать на любые другие запросы. Создавая для каждого бота отдельный `threading.Thread`, мы выносим всю блокирующую работу в фон, сохраняя API полностью отзывчивым. Когда бот завершает свою работу (сам или по команде), поток завершается, и бот удаляется из словаря `active_bots`.

---

### 3. Архитектура обработки аудиопотока и его настройка

Это самая сложная и интересная часть системы. Вот как звук проходит от Google Meet до `.wav` файла на нашем диске.

**Цепочка прохождения звука:**

1.  **Источник (Google Meet):** Другие участники говорят во встрече. Google Meet рендерит их голоса в аудиопоток.
2.  **Воспроизведение (Chrome):** Наш браузер Chrome, работающий внутри контейнера, получает этот аудиопоток и пытается его воспроизвести.
3.  **Перехват (PulseAudio Sink):** В `entrypoint.sh` мы создаем **виртуальное устройство вывода звука** под названием `meet_sink` и делаем его устройством _по умолчанию_ в системе. Chrome не знает, что это "ненастоящие" колонки, и послушно направляет весь свой звук в этот `meet_sink`.
4.  **Мониторинг (PulseAudio Source):** Одновременно мы создаем **виртуальный микрофон** `meet_mic`. Его ключевая особенность в том, что его источником (`master`) является _монитор_ нашего `meet_sink`. Проще говоря, этот "микрофон" слушает всё, что проигрывается через "колонки" `meet_sink`. **Это сердце всего механизма перехвата.**
5.  **Захват (Sounddevice):** В `api/meet_listener.py` библиотека `sounddevice` ищет в системе устройство ввода (микрофон) по имени, указанному в `config.MEET_INPUT_DEVICE_NAME`. Она находит наш `meet_mic` и начинает слушать аудиопоток уже из него.
6.  **Буферизация (Queue):** Захваченные сырые аудиоданные немедленно помещаются в потокобезопасную очередь (`queue.Queue`).
7.  **Анализ (VAD):** В отдельном потоке метод `_process_audio_stream` постоянно извлекает данные из очереди и анализирует их с помощью `webrtcvad` (Voice Activity Detection), определяя, содержат ли они речь или тишину.
8.  **Сохранение (.wav):** Как только VAD обнаруживает достаточно длинный промежуток тишины после отрезка речи, он считает "фразу" законченной, объединяет все накопленные голосовые фрагменты и сохраняет их в виде отдельного `.wav` файла.

**Работа VAD-цикла и рекомендации по настройке:**

Цикл в `_process_audio_stream` — это наш "умный диктофон". Его качество напрямую зависит от двух параметров из `config.py`:

- `MEET_VAD_AGGRESSIVENESS`: Это "агрессивность" или "строгость" VAD. Принимает значения от 0 до 3.

  - `0`: Очень мягкий режим, будет считать речью почти любой несильный шум.
  - `3`: Очень строгий режим, будет отфильтровывать фоновый шум, тихую речь и помечать как "речь" только четкие голосовые сигналы.

- `MEET_PAUSE_THRESHOLD_S`: Это порог тишины в секундах, который VAD считает концом фразы.

**Рекомендации по настройке:**

Вам может понадобиться изменять эти параметры в зависимости от характера встречи:

- **Для шумной встречи с плохим качеством звука:**

  - Увеличьте `MEET_VAD_AGGRESSIVENESS` до `2` или `3`, чтобы VAD активнее отсекал фоновый шум и не сохранял его как полезный сигнал.

- **Для лекции или доклада, где спикер делает долгие паузы:**

  - Увеличьте `MEET_PAUSE_THRESHOLD_S` до `1.5` или `2.0` секунды. Это предотвратит нарезку одной логической фразы на несколько файлов только из-за того, что спикер сделал паузу.

- **Для быстрой дискуссии или диалога:**
  - Уменьшите `MEET_PAUSE_THRESHOLD_S` до `0.5`-`0.7` секунды. Это позволит получать более короткие и атомарные аудио-фрагменты, соответствующие репликам разных людей.

Начинать всегда стоит со значений по умолчанию, а затем тюнинговать их, анализируя получаемые аудио-чанки.
